{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "def load_pickle(file):\n",
    "     with open(file, mode='rb') as f:\n",
    "        try:\n",
    "            obj = pickle.load(f)\n",
    "            return obj\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "mnist_X = load_pickle('mnist_X.pickle')\n",
    "mnist_y = load_pickle('mnist_y.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.where(x>0,x,0)\n",
    "\n",
    "def deriv_ReLU(x):\n",
    "    return np.where(x>0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    return ex/np.sum(ex,axis=1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(mnist_X[:10000], mnist_y[:10000],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, in_dim, out_dim, function, deriv_function):\n",
    "        self.W = np.random.uniform(low= -0.08, high= 0.08, size=(in_dim, out_dim)).astype(\"float32\")\n",
    "        self.b = np.zeros(out_dim).astype(\"float32\")\n",
    "        self.function = function\n",
    "        self.deriv_function = deriv_function\n",
    "        self.u = None\n",
    "        self.delta = None\n",
    "        \n",
    "    def f_prop(self, x):\n",
    "        self.u = np.dot(x, self.W) + self.b\n",
    "        self.z = self.function(self.u)\n",
    "        return self.z\n",
    "    \n",
    "    def b_prop(self, delta, W):\n",
    "        self.delta = self.deriv_function(self.u)*np.dot(delta, W.T)\n",
    "        return self.delta\n",
    "    \n",
    "def f_props(layers, x):\n",
    "    z = x\n",
    "    for layer in layers:\n",
    "        z = layer.f_prop(z)\n",
    "    return z\n",
    "\n",
    "def b_props(layers, delta):\n",
    "    for i, layer in enumerate(layers[::-1]):\n",
    "        if i == 0:\n",
    "            layer.delta = delta\n",
    "        else:\n",
    "            delta = layer.b_prop(delta, _W)\n",
    "        _W = layer.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X, t, eps=1.,l=1e-5):\n",
    "    y = f_props(layers, X)\n",
    "    delta = y - t\n",
    "    b_props(layers, delta)\n",
    "\n",
    "    z = X\n",
    "    for i, layer in enumerate(layers):\n",
    "        dW = np.dot(z.T, layer.delta)+l*layer.W\n",
    "        db = np.dot(np.ones(z.shape[0]), layer.delta)+l*layer.b\n",
    "        layer.W = layer.W - eps*dW\n",
    "        layer.b = layer.b - eps*db\n",
    "        z = layer.z\n",
    "\n",
    "def test(X, t):\n",
    "    y = f_props(layers, X)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = train_X.mean(axis=0)\n",
    "std = train_X.std(axis=0)\n",
    "train_X_std = train_X\n",
    "test_X_std = test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44225\n",
      "0.425\n",
      "0.86775\n",
      "0.8335\n",
      "0.965625\n",
      "0.9375\n",
      "0.971625\n",
      "0.94\n",
      "0.980375\n",
      "0.9455\n",
      "0.985625\n",
      "0.947\n",
      "0.98925\n",
      "0.946\n",
      "0.992\n",
      "0.948\n",
      "0.99475\n",
      "0.9505\n",
      "0.996\n",
      "0.9515\n",
      "0.996875\n",
      "0.951\n",
      "0.9985\n",
      "0.9525\n",
      "0.9995\n",
      "0.953\n",
      "1.0\n",
      "0.953\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.9545\n",
      "1.0\n",
      "0.9545\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.9545\n",
      "1.0\n",
      "0.955\n",
      "1.0\n",
      "0.955\n",
      "1.0\n",
      "0.9545\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.9535\n",
      "1.0\n",
      "0.9535\n",
      "1.0\n",
      "0.9535\n",
      "1.0\n",
      "0.9535\n",
      "1.0\n",
      "0.9535\n",
      "1.0\n",
      "0.9535\n",
      "1.0\n",
      "0.9535\n",
      "1.0\n",
      "0.9535\n",
      "1.0\n",
      "0.9535\n",
      "1.0\n",
      "0.9535\n",
      "1.0\n",
      "0.9535\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.9535\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.954\n",
      "1.0\n",
      "0.9545\n",
      "1.0\n",
      "0.9545\n",
      "1.0\n",
      "0.9545\n",
      "1.0\n",
      "0.9545\n",
      "1.0\n",
      "0.9545\n",
      "1.0\n",
      "0.9545\n",
      "1.0\n",
      "0.9545\n",
      "1.0\n",
      "0.955\n",
      "1.0\n",
      "0.9545\n",
      "1.0\n",
      "0.955\n",
      "1.0\n",
      "0.9555\n",
      "1.0\n",
      "0.955\n",
      "1.0\n",
      "0.9555\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.9555\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.956\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n",
      "1.0\n",
      "0.9565\n"
     ]
    }
   ],
   "source": [
    "layers = [Layer(784, 300, ReLU, deriv_ReLU),\n",
    "          Layer(300, 10, softmax, None)]\n",
    "batch = 101\n",
    "for epoch in range(100):\n",
    "    i = 0\n",
    "    while i+batch < len(train_X_std):\n",
    "        train(train_X_std[i:i+batch], train_y[i:i+batch],1e-2)\n",
    "        i+=batch\n",
    "    train(train_X_std[i:], train_y[i:],1e-1)\n",
    "    pred_train_y = test(train_X_std, train_y)\n",
    "    print(accuracy_score(np.argmax(pred_train_y,axis=1), np.argmax(train_y,axis=1)))\n",
    "    pred_y = test(test_X_std, test_y)\n",
    "    print(accuracy_score(np.argmax(pred_y,axis=1), np.argmax(test_y,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers[0].b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
